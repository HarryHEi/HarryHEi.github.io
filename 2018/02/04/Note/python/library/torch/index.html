<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="Ben Wong,wenbinben@gmail.com"><title>torch · Harryx</title><meta name="description" content="文档
TensorsTensors和NumPy的ndarrays(比如由numpy.array()方法创建的实例)类似，并且可以在GPU上加速计算。
所有支持的操作
autogradPyTorch神经网络最核心的是autograd包，提供支持Tensors所有操作方式的自动区分，是一个运行时定义的框"><meta name="keywords" content="Hexo,HTML,Ben,CSS,安卓,android,Linux,linuxdeepin"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="short icon" href="/images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/blog_basic.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"></head><body><div class="sidebar animated fadeInDown"><div class="logo-title"><div class="title"><img src="/images/logo@2x.png" style="width:127px;"><h3 title=""><a href="/">Harryx</a></h3><div class="description"><p>good good study good good play~</p></div></div></div><ul class="social-links"><li><a href="https://twitter.com/harryx520"><i class="fa fa-twitter"></i></a></li><li><a href="http://weibo.com/Booooyakasha"><i class="fa fa-weibo"></i></a></li></ul><div class="footer"><a target="_blank" href="/"><span>Theme by </span></a><a href="https://www.caicai.me"> CaiCai </a><span>&</span><a href="https://github.com/Ben02/hexo-theme-Anatole"> Ben</a><div class="by_farbox"><a href="https://hexo.io/zh-cn/" target="_blank">Proudly published with Hexo&#65281;</a></div></div></div><div class="main"><div class="page-top animated fadeInDown"><div class="nav"><li><a href="/">首页</a></li><li><a href="/about">关于</a></li><li><a href="/archives">归档</a></li><li><a href="/links">友链</a></li></div><div class="information"><div class="back_btn"><li><a onclick="window.history.go(-1)" class="fa fa-chevron-left"> </a></li></div><div class="avatar"><img src="http://7xrooc.com1.z0.glb.clouddn.com/avatar.jpg"></div></div></div><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post animated fadeInDown"><div class="post-title"><h3><a>torch</a></h3></div><div class="post-content"><p><a href="http://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html" target="_blank" rel="external">文档</a></p>
<h1 id="Tensors"><a href="#Tensors" class="headerlink" title="Tensors"></a>Tensors</h1><p>Tensors和NumPy的ndarrays(比如由<code>numpy.array()</code>方法创建的实例)类似，并且可以在GPU上加速计算。</p>
<p><a href="http://pytorch.org/docs/master/torch.html" target="_blank" rel="external">所有支持的操作</a></p>
<h1 id="autograd"><a href="#autograd" class="headerlink" title="autograd"></a>autograd</h1><p>PyTorch神经网络最核心的是autograd包，提供支持Tensors所有操作方式的自动区分，是一个运行时定义的框架。</p>
<h2 id="Variable"><a href="#Variable" class="headerlink" title="Variable"></a>Variable</h2><p><code>autograd.Variable</code>是这个包的核心，包装了一个Tensor，支持Tensor的所有操作。一旦完成计算，可以调用<code>.backward()</code>自动计算梯度。</p>
<p>可以通过<code>.data</code>属性获取原始数据，梯度可以通过<code>.grad</code>属性获取。</p>
<p>还有一个非常重要的类<code>Function</code>，和<code>Variable</code>连接并建立非环状图表，编写完整的计算历史。每个Variable有一个<code>.grad_fn</code>属性保存创建这个Variable的Function的引用，除非是由用户创建的Variables，它们的<code>grad_fn</code>是None。</p>
<p>如果想要计算衍生物，可以调用<code>Variable.backward()</code>，如果<code>Variable</code>是标量，比如一元数据，<code>backward()</code>就不需要指定参数，否则，必须指定<code>grad_output</code>参数匹配Tensor形状。</p>
<p>创建一个Variable<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">In[31]: x=Variable(torch.ones(2,2), requires_grad=True)</div><div class="line">In[32]: x</div><div class="line">Out[32]: </div><div class="line">Variable containing:</div><div class="line"> 1  1</div><div class="line"> 1  1</div><div class="line">[torch.FloatTensor of size 2x2]</div></pre></td></tr></table></figure></p>
<p>进行一些操作<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">In[33]: y = x * 2</div><div class="line">In[34]: y</div><div class="line">Out[34]: </div><div class="line">Variable containing:</div><div class="line"> 2  2</div><div class="line"> 2  2</div><div class="line">[torch.FloatTensor of size 2x2]</div></pre></td></tr></table></figure></p>
<p>这里y是由计算的结果创建的，所有它具有<code>grad_fn</code>参数<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">y.grad_fn</div><div class="line">Out[35]: &lt;torch.autograd.function.MulConstantBackward at 0x1eb95684618&gt;</div></pre></td></tr></table></figure></p>
<h2 id="Gradients"><a href="#Gradients" class="headerlink" title="Gradients"></a>Gradients</h2><p>做一些操作，这里out是计算z的平均值:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">In[36]: z=y*y*3</div><div class="line">In[37]: z</div><div class="line">Out[37]: </div><div class="line">Variable containing:</div><div class="line"> 12  12</div><div class="line"> 12  12</div><div class="line">[torch.FloatTensor of size 2x2]</div><div class="line">In[38]: out=z.mean()</div><div class="line">In[39]: out</div><div class="line">Out[39]: </div><div class="line">Variable containing:</div><div class="line"> 12</div><div class="line">[torch.FloatTensor of size 1]</div></pre></td></tr></table></figure></p>
<p>回过头调用<code>out.backward()</code>也等同于<code>out.backward(torch.Tensor([1.0]))</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">In[40]: out.backward()</div><div class="line">In[41]: x.grad</div><div class="line">Out[41]: </div><div class="line">Variable containing:</div><div class="line"> 6  6</div><div class="line"> 6  6</div><div class="line">[torch.FloatTensor of size 2x2]</div></pre></td></tr></table></figure>
<p>已知out等于z的平均值，z等于y的平方乘以3，y等于2乘以x，并且当x等于1时z等于12。</p>
<p>列出out和x的表达式: <code>out = 12x^2</code> ，求导得: <code>6</code></p>
<p>与最后的结果相同。</p>
<p>范数:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">In[42]: x=torch.randn(3)</div><div class="line">In[43]: x=Variable(x, requires_grad=True)</div><div class="line">In[44]: y=x*2</div><div class="line">In[45]: while y.data.norm() &lt; 1000:</div><div class="line">   ...:     y = y * 2</div><div class="line">   ...:     </div><div class="line">In[46]: y</div><div class="line">Out[46]: </div><div class="line">Variable containing:</div><div class="line">  949.9868</div><div class="line">-1183.3439</div><div class="line"> 1207.7928</div><div class="line">[torch.FloatTensor of size 3]</div></pre></td></tr></table></figure></p>
<p>调用backward()<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">In[47]: gradients = torch.FloatTensor([0.1, 1.0, 0.0001])</div><div class="line">In[48]: y.backward(gradients)</div><div class="line">In[49]: x.grad</div><div class="line">Out[49]: </div><div class="line">Variable containing:</div><div class="line">  102.4000</div><div class="line"> 1024.0000</div><div class="line">    0.1024</div><div class="line">[torch.FloatTensor of size 3]</div></pre></td></tr></table></figure></p>
</div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2018-02-04</span><i class="fa fa-tag"></i><a href="/tags/python/" title="python" class="tag">python </a></div></div></div></div><div class="share"><div class="evernote"><a href="javascript:(function(){EN_CLIP_HOST='http://www.evernote.com';try{var%20x=document.createElement('SCRIPT');x.type='text/javascript';x.src=EN_CLIP_HOST+'/public/bookmarkClipper.js?'+(new%20Date().getTime()/100000);document.getElementsByTagName('head')[0].appendChild(x);}catch(e){location.href=EN_CLIP_HOST+'/clip.action?url='+encodeURIComponent(location.href)+'&amp;title='+encodeURIComponent(document.title);}})();" ref="nofollow" target="_blank" class="fa fa-bookmark"></a></div><div class="weibo"><a href="javascript:void((function(s,d,e){try{}catch(e){}var f='http://service.weibo.com/share/share.php?',u=d.location.href,p=['url=',e(u),'&amp;title=',e(d.title),'&amp;appkey=2924220432'].join('');function a(){if(!window.open([f,p].join(''),'mb',['toolbar=0,status=0,resizable=1,width=620,height=450,left=',(s.width-620)/2,',top=',(s.height-450)/2].join('')))u.href=[f,p].join('');};if(/Firefox/.test(navigator.userAgent)){setTimeout(a,0)}else{a()}})(screen,document,encodeURIComponent));" class="fa fa-weibo"></a></div><div class="twitter"><a href="http://twitter.com/home?status=,http://yoursite.com/2018/02/04/Note/python/library/torch/,Harryx,torch,;" class="fa fa-twitter"></a></div></div><div class="pagination"><ul class="clearfix"><li class="next pagbuttons"><a role="navigation" href="/2018/02/03/Note/tools/cmake/" title="cmake" class="btn">下一篇</a></li></ul></div></div></div></div></div><script src="/js/jquery.js"></script><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script></body></html>