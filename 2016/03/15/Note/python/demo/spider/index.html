<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="Ben Wong,wenbinben@gmail.com"><title>python_spider · Harryx</title><meta name="description" content="爬虫入门123456789#!/usr/bin/env python# -*- coding:utf-8 -*-&amp;quot;这是个小爬虫&amp;quot;import urllib2response = urllib2.urlopen(&amp;quot;http://herui.blog-harryx.cn&amp;q"><meta name="keywords" content="Hexo,HTML,Ben,CSS,安卓,android,Linux,linuxdeepin"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="short icon" href="/images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/blog_basic.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"></head><body><div class="sidebar animated fadeInDown"><div class="logo-title"><div class="title"><img src="/images/logo@2x.png" style="width:127px;"><h3 title><a href="/">Harryx</a></h3><div class="description"><p>good good study good good play~</p></div></div></div><ul class="social-links"><li><a href="https://twitter.com/harryx520"><i class="fa fa-twitter"></i></a></li><li><a href="http://weibo.com/Booooyakasha"><i class="fa fa-weibo"></i></a></li></ul><div class="footer"><a target="_blank" href="/"><span>Theme by </span></a><a href="https://www.caicai.me"> CaiCai </a><span>&</span><a href="https://github.com/Ben02/hexo-theme-Anatole"> Ben</a><div class="by_farbox"><a href="http://beian.miit.gov.cn/" target="_blank">苏ICP备19072417号-1</a></div></div></div><div class="main"><div class="page-top animated fadeInDown"><div class="nav"><li><a href="/">首页</a></li><li><a href="/about">关于</a></li><li><a href="/archives">归档</a></li><li><a href="/links">友链</a></li></div><div class="information"><div class="back_btn"><li><a class="fa fa-chevron-left" onclick="window.history.go(-1)"> </a></li></div><div class="avatar"><img src="/images/avator.jpg"></div></div></div><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post animated fadeInDown"><div class="post-title"><h3><a>python_spider</a></h3></div><div class="post-content"><h1 id="爬虫入门"><a href="#爬虫入门" class="headerlink" title="爬虫入门"></a>爬虫入门</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/env python</span><br><span class="line"># -*- coding:utf-8 -*-</span><br><span class="line">&quot;这是个小爬虫&quot;</span><br><span class="line"></span><br><span class="line">import urllib2</span><br><span class="line"></span><br><span class="line">response = urllib2.urlopen(&quot;http://herui.blog-harryx.cn&quot;)</span><br><span class="line"></span><br><span class="line">print response.read()</span><br></pre></td></tr></table></figure>
<p>直接调用urlopen函数返回一个respons对象，并用.read()函数操作这个respon对象<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">request = urllib2.Request(&quot;http://herui.blog-harryx.cn&quot;)</span><br><span class="line">response = urllib2.urlopen(request)</span><br></pre></td></tr></table></figure></p>
<p>使用Request()函数构造request，可以额外发送其他数据或信息<br>这里我们先设置为空字典<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">from urllib2 import Request, urlopen, URLError, HTTPError  </span><br><span class="line">import sys</span><br><span class="line"></span><br><span class="line">header = &#123;    </span><br><span class="line"></span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line">request = Request(&quot;http://herui.blog-harryx.cn&quot;, headers=header)</span><br><span class="line"></span><br><span class="line">try:</span><br><span class="line">    response = urlopen(request)</span><br><span class="line"></span><br><span class="line">except URLError, e:</span><br><span class="line">    if hasattr(e, &quot;code&quot;):</span><br><span class="line">        print &quot;HTTP error: &quot; + str(e.code)</span><br><span class="line">    elif hasattr(e, &quot;reason&quot;):</span><br><span class="line">        print e.reason</span><br><span class="line"></span><br><span class="line">    sys.exit(1)</span><br><span class="line"></span><br><span class="line">print response.read()</span><br></pre></td></tr></table></figure></p>
<p>这里使用try-except语句检验错误<br>要注意URLError包含HTTPError，要先检验HTTPError<br>或者使用hasattr()函数检验类是否包含指定参数<br>这里向服务器发出的请求是GET请求</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">from urllib2 import Request, urlopen, URLError, HTTPError  </span><br><span class="line">from urllib import urlencode</span><br><span class="line">import sys</span><br><span class="line"></span><br><span class="line">url = &quot;http://localhost:5000&quot;</span><br><span class="line"></span><br><span class="line">values = &#123;</span><br><span class="line">    &quot;name&quot;:&quot;harryx&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">header = &#123;    </span><br><span class="line"></span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line">data = urlencode(values)</span><br><span class="line">request = Request(url,data=data, headers=header)</span><br><span class="line"></span><br><span class="line">try:</span><br><span class="line">    response = urlopen(request)</span><br><span class="line"></span><br><span class="line">except URLError, e:</span><br><span class="line">    if hasattr(e, &quot;code&quot;):</span><br><span class="line">        print &quot;HTTP error: &quot; + str(e.code)</span><br><span class="line">    elif hasattr(e, &quot;reason&quot;):</span><br><span class="line">        print e.reason</span><br><span class="line"></span><br><span class="line">    sys.exit(1)</span><br><span class="line"></span><br><span class="line">print response.read()</span><br></pre></td></tr></table></figure>
<p>加入data参数，向本地服务器发出请求<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1 - - [16/Mar/2016 15:27:06] &quot;POST / HTTP/1.1&quot; 200 -</span><br></pre></td></tr></table></figure></p>
<p>发出的是POST请求<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./spider.py &gt; hello.html</span><br></pre></td></tr></table></figure></p>
<p>打开网页，可以看到对话框填入了字符串“harryx”</p>
<h2 id="geturl"><a href="#geturl" class="headerlink" title="geturl()"></a>geturl()</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">response.geturl()</span><br></pre></td></tr></table></figure>
<p>geturl()用来获取真实的URL，urlopen可能会HTTP重定向</p>
<h2 id="info"><a href="#info" class="headerlink" title="info()"></a>info()</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print response.info()</span><br></pre></td></tr></table></figure>
<p>返回服务器的响应报文首部，包含获取网页的信息<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">Server: GitHub.com</span><br><span class="line">Content-Type: text/html; charset=utf-8</span><br><span class="line">Last-Modified: Sun, 13 Mar 2016 08:07:00 GMT</span><br><span class="line">Access-Control-Allow-Origin: *</span><br><span class="line">Expires: Tue, 15 Mar 2016 13:13:57 GMT</span><br><span class="line">Cache-Control: max-age=600</span><br><span class="line">X-GitHub-Request-Id: 17EB2B31:0345:1A183C4:56E8083D</span><br><span class="line">Content-Length: 27069</span><br><span class="line">Accept-Ranges: bytes</span><br><span class="line">Date: Wed, 16 Mar 2016 11:18:33 GMT</span><br><span class="line">Via: 1.1 varnish</span><br><span class="line">Age: 539</span><br><span class="line">Connection: close</span><br><span class="line">X-Served-By: cache-ams4127-AMS</span><br><span class="line">X-Cache: HIT</span><br><span class="line">X-Cache-Hits: 1</span><br><span class="line">X-Timer: S1458127113.611546,VS0,VE0</span><br><span class="line">Vary: Accept-Encoding</span><br><span class="line">X-Fastly-Request-ID: ef7713a01a3cf84afdd68ff2640410d72a1774c1</span><br></pre></td></tr></table></figure></p>
<h2 id="代理服务器"><a href="#代理服务器" class="headerlink" title="代理服务器"></a>代理服务器</h2><p>使用代理服务器的方法如下<br>很好很强大<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">proxy_handler = ProxyHandler(&#123;&quot;http&quot; :&apos;http://121.193.143.249:80&apos;&#125;)  </span><br><span class="line">null_proxy_handler = ProxyHandler(&#123;&#125;)  </span><br><span class="line">enable_prosy = False</span><br><span class="line"></span><br><span class="line">if enable_prosy:</span><br><span class="line">    opener = build_opener(proxy_handler)</span><br><span class="line">else:</span><br><span class="line">    opener = build_opener(null_proxy_handler)</span><br><span class="line"></span><br><span class="line">data = urlencode(values)</span><br><span class="line">request = Request(url,data=None, headers=header)</span><br><span class="line">response = opener.open(request,timeout=20)</span><br></pre></td></tr></table></figure></p>
<h2 id="cookielib"><a href="#cookielib" class="headerlink" title="cookielib"></a>cookielib</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import cookielib</span><br><span class="line">cookie = cookielib.CookieJar()</span><br><span class="line">cookie_handler = HTTPCookieProcessor(cookie)</span><br><span class="line">opener = build_opener(cookie_handler)</span><br></pre></td></tr></table></figure>
<p>注意的是,如果同时使用到代理服务器,需要同时添加proxy_handle<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">opener = build_opener(cookie_handler, proxy_handler)</span><br></pre></td></tr></table></figure></p>
<h1 id="爬自己本地的flask写的web"><a href="#爬自己本地的flask写的web" class="headerlink" title="爬自己本地的flask写的web"></a>爬自己本地的flask写的web</h1><h2 id="用httpfox查看自己发送的包"><a href="#用httpfox查看自己发送的包" class="headerlink" title="用httpfox查看自己发送的包"></a>用httpfox查看自己发送的包</h2><blockquote>
<p>csrf_token:1458359238##98ca41f600896093e2e7b12e488d8cd9eb74c3db<br>name:lalala<br>submit:Submit</p>
</blockquote>
<p>所以我定义一个字典<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">values = &#123;</span><br><span class="line">    &quot;csrf_token&quot;:None,</span><br><span class="line">    &quot;name&quot;:&quot;Python&quot;,</span><br><span class="line">    &quot;submit&quot;:&quot;Submit&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>csrf_token是个随机值，第一次访问页面时获得，所以后面需要用正则表达式获取，<br>先不管。<br>查看headers里面的内容，照写<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">header = &#123;    </span><br><span class="line">    &quot;User-Agent&quot;:user_agent,</span><br><span class="line">    &quot;Host&quot;:&quot;localhost:5000&quot;,</span><br><span class="line">    &quot;Accept&quot;:&quot;text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8&quot;,</span><br><span class="line">    &quot;Accept-Language&quot;:&quot;en-US,en;q=0.5&quot;,</span><br><span class="line">    &quot;Accept-Encoding&quot;:&quot;gzip, deflate&quot;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure></p>
<p>header里面还有cookie这一项，所以用cookielib库<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import cookielib</span><br><span class="line"></span><br><span class="line">cookie = cookielib.CookieJar()</span><br><span class="line">opener = urllib2.build_opener(urllib2.HTTPCookieProcessor(cookie))</span><br><span class="line">request = urllib2.Request(url, headers=header)</span><br><span class="line">response = opener.open(request,timeout=20)</span><br></pre></td></tr></table></figure></p>
<p>这里先读取一次页面，获得cookie，同时用正则表达式获得csrf_token的值<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">values[&quot;csrf_token&quot;] = str(re.findall(&apos;\d&#123;10&#125;##\w*&apos;,response.read())).split(&quot;\&apos;&quot;)[1]</span><br></pre></td></tr></table></figure></p>
<p>然后使用urllib库里面的urlencode对values的值进行编码<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data = urllib.urlencode(values)</span><br></pre></td></tr></table></figure></p>
<p>最后读取一次页面，同时上传data数据<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">try:</span><br><span class="line">    request = urllib2.Request(url,data=data, headers=header)</span><br><span class="line">    response = opener.open(request,timeout=20)</span><br><span class="line"></span><br><span class="line">except urllib2.URLError, e:</span><br><span class="line">    if hasattr(e, &quot;code&quot;):</span><br><span class="line">        print &quot;HTTP error: &quot; + str(e.code)</span><br><span class="line">    elif hasattr(e, &quot;reason&quot;):</span><br><span class="line">        print e.reason</span><br><span class="line"></span><br><span class="line">    sys.exit(1)</span><br><span class="line"></span><br><span class="line">print response.read()</span><br></pre></td></tr></table></figure></p>
<p>可以在web端看到一次POST<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1 - - [19/Mar/2016 10:47:26] &quot;POST / HTTP/1.1&quot; 302 -</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;div class=&quot;page-header&quot;&gt;</span><br><span class="line">    &lt;h1&gt;Hello, Python!&lt;/h1&gt;</span><br><span class="line">    </span><br><span class="line">    &lt;p&gt;Pleased to meet you!&lt;/p&gt;</span><br><span class="line">    </span><br><span class="line">&lt;/div&gt;</span><br></pre></td></tr></table></figure>
<p>成功</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p> <a href="http://blog.csdn.net/column/details/why-bug.html" target="_blank" rel="noopener">http://blog.csdn.net/column/details/why-bug.html</a></p>
</div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2016-03-15</span><i class="fa fa-tag"></i><a class="tag" href="/tags/python/" title="python">python </a><a class="tag" href="/tags/spider/" title="spider">spider </a></div></div></div></div><div class="share"><div class="evernote"><a class="fa fa-bookmark" href="javascript:(function(){EN_CLIP_HOST='http://www.evernote.com';try{var%20x=document.createElement('SCRIPT');x.type='text/javascript';x.src=EN_CLIP_HOST+'/public/bookmarkClipper.js?'+(new%20Date().getTime()/100000);document.getElementsByTagName('head')[0].appendChild(x);}catch(e){location.href=EN_CLIP_HOST+'/clip.action?url='+encodeURIComponent(location.href)+'&amp;title='+encodeURIComponent(document.title);}})();" ref="nofollow" target="_blank"></a></div><div class="weibo"><a class="fa fa-weibo" href="javascript:void((function(s,d,e){try{}catch(e){}var f='http://service.weibo.com/share/share.php?',u=d.location.href,p=['url=',e(u),'&amp;title=',e(d.title),'&amp;appkey=2924220432'].join('');function a(){if(!window.open([f,p].join(''),'mb',['toolbar=0,status=0,resizable=1,width=620,height=450,left=',(s.width-620)/2,',top=',(s.height-450)/2].join('')))u.href=[f,p].join('');};if(/Firefox/.test(navigator.userAgent)){setTimeout(a,0)}else{a()}})(screen,document,encodeURIComponent));"></a></div><div class="twitter"><a class="fa fa-twitter" href="http://twitter.com/home?status=,http://yoursite.com/2016/03/15/Note/python/demo/spider/,Harryx,python_spider,;"></a></div></div><div class="pagination"><ul class="clearfix"><li class="pre pagbuttons"><a class="btn" role="navigation" href="/2016/03/19/Note/python/library/coroutine/threading/" title="多线程">上一篇</a></li><li class="next pagbuttons"><a class="btn" role="navigation" href="/2016/03/13/Note/python/library/web/flask/flask_mail/" title="flask_send_mail">下一篇</a></li></ul></div></div></div></div></div><script src="/js/jquery.js"></script><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script></body></html>